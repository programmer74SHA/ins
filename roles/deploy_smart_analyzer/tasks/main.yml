---
# =============================================================================
# DEPLOY SMART ANALYZER ROLE - Main Tasks
# =============================================================================
# This role deploys the Smart Analyzer AI service with all dependencies
# including GPU validation, model verification, and health checks
# =============================================================================

- name: Include pre-deployment validation tasks
  ansible.builtin.include_tasks: validate.yml
  tags: ['validate']

- name: Ensure deployment directory exists
  ansible.builtin.file:
    path: "{{ smart_analyzer_deploy_dir }}"
    state: directory
    mode: '0755'

- name: Ensure prompts directory exists
  ansible.builtin.file:
    path: "{{ smart_analyzer_prompts_volume }}"
    state: directory
    mode: '0755'

- name: Ensure qdrant storage directory exists
  ansible.builtin.file:
    path: "{{ smart_analyzer_qdrant_volume }}"
    state: directory
    mode: '0755'

- name: Ensure models directory exists
  ansible.builtin.file:
    path: "{{ smart_analyzer_deploy_dir }}/models"
    state: directory
    mode: '0755'

- name: Set proper permissions on models directory
  ansible.builtin.file:
    path: "{{ smart_analyzer_deploy_dir }}/models"
    state: directory
    mode: '0775'
    recurse: true
  when: smart_analyzer_fix_model_permissions | default(true)

- name: Ensure haproxy config directory exists
  ansible.builtin.file:
    path: "{{ smart_analyzer_deploy_dir }}/infra_config/haproxy"
    state: directory
    mode: '0755'

- name: Copy haproxy configuration files
  ansible.builtin.template:
    src: haproxy.cfg.j2
    dest: "{{ smart_analyzer_deploy_dir }}/infra_config/haproxy/haproxy.cfg"
    mode: '0644'

- name: Create AI infrastructure network
  community.docker.docker_network:
    name: "{{ smart_analyzer_network_name }}"
    state: present
  when: smart_analyzer_network_external

- name: Create esnet network
  community.docker.docker_network:
    name: "{{ smart_analyzer_esnet_name }}"
    state: present
  when: smart_analyzer_esnet_external

- name: Verify networks were created
  ansible.builtin.command: docker network ls --format '{{ '{{' }}.Name{{ '}}' }}'
  register: docker_networks_check
  changed_when: false

- name: Fail if required networks don't exist
  ansible.builtin.fail:
    msg: "Required Docker network '{{ item }}' does not exist"
  when: item not in docker_networks_check.stdout_lines
  loop:
    - "{{ smart_analyzer_network_name }}"

- name: Check if AI model exists
  ansible.builtin.stat:
    path: "{{ smart_analyzer_deploy_dir }}/models/{{ smart_analyzer_ai_model_path | basename }}"
  register: ai_model_check
  when: smart_analyzer_verify_model_exists | default(true)

- name: Display model status
  ansible.builtin.debug:
    msg: "AI Model {{ 'found' if ai_model_check.stat.exists else 'NOT FOUND' }} at {{ smart_analyzer_deploy_dir }}/models/"
  when: smart_analyzer_verify_model_exists | default(true)

- name: Template docker-compose file
  ansible.builtin.template:
    src: docker-compose.yml.j2
    dest: "{{ smart_analyzer_deploy_dir }}/docker-compose.yml"
    mode: '0644'

- name: Template .env file
  ansible.builtin.template:
    src: .env.j2
    dest: "{{ smart_analyzer_deploy_dir }}/.env"
    mode: '0600'

# CRITICAL: This task was missing in the original role
- name: Deploy Smart Analyzer with Docker Compose
  ansible.builtin.include_tasks: smart-analyzer-docker-deploy.yml
  tags: ['deploy']

- name: Wait for AI service to be ready
  ansible.builtin.wait_for:
    host: localhost
    port: "{{ smart_analyzer_ai_service_port }}"
    delay: 10
    timeout: 300
    state: started

- name: Wait for Qdrant to be ready
  ansible.builtin.wait_for:
    host: localhost
    port: "{{ smart_analyzer_qdrant_port }}"
    delay: 5
    timeout: 120
    state: started

- name: Wait for HAProxy to be ready
  ansible.builtin.wait_for:
    host: localhost
    port: "{{ smart_analyzer_haproxy_port }}"
    delay: 5
    timeout: 60
    state: started

- name: Check AI service health
  ansible.builtin.uri:
    url: "http://localhost:{{ smart_analyzer_ai_service_port }}/health"
    method: GET
    status_code: [200, 404]
  register: ai_health
  until: ai_health.status in [200, 404]
  retries: 10
  delay: 5
  failed_when: false

- name: Check Qdrant health
  ansible.builtin.uri:
    url: "http://localhost:{{ smart_analyzer_qdrant_port }}/health"
    method: GET
    status_code: 200
  register: qdrant_health
  until: qdrant_health.status == 200
  retries: 5
  delay: 3

- name: Verify container status
  ansible.builtin.shell: |
    docker compose ps --format json
  args:
    chdir: "{{ smart_analyzer_deploy_dir }}"
  register: container_status
  changed_when: false

- name: Parse container status
  ansible.builtin.set_fact:
    containers_running: "{{ container_status.stdout | from_json | selectattr('State', 'equalto', 'running') | list }}"

- name: Display container status
  ansible.builtin.debug:
    msg: "{{ containers_running | length }} containers are running"

- name: Run initial prompt seeding (if configured)
  ansible.builtin.include_tasks: seed_prompts.yml
  when: smart_analyzer_seed_prompts | default(false)
  tags: ['seed']

- name: Display deployment information
  ansible.builtin.debug:
    msg:
      - "============================================"
      - "Smart Analyzer Deployment Complete!"
      - "============================================"
      - "AI Service: http://{{ ansible_default_ipv4.address }}:{{ smart_analyzer_ai_service_port }}"
      - "Qdrant Vector DB: http://{{ ansible_default_ipv4.address }}:{{ smart_analyzer_qdrant_port }}"
      - "HAProxy: http://{{ ansible_default_ipv4.address }}:{{ smart_analyzer_haproxy_port }}"
      - "AI Launcher 1: http://{{ ansible_default_ipv4.address }}:{{ smart_analyzer_ai_launcher_1_port }}"
      - "AI Launcher 2: http://{{ ansible_default_ipv4.address }}:{{ smart_analyzer_ai_launcher_2_port }}"
      - "Embeddings: http://{{ ansible_default_ipv4.address }}:{{ smart_analyzer_embeddings_port }}"
      - "Model: {{ smart_analyzer_ai_model_path }}"
      - "Containers Running: {{ containers_running | length }}"
      - "============================================"

- name: Display GPU information (if available)
  ansible.builtin.shell: nvidia-smi --query-gpu=name,driver_version,memory.total --format=csv,noheader
  register: gpu_info
  changed_when: false
  failed_when: false

- name: Show GPU details
  ansible.builtin.debug:
    msg: "GPU Info: {{ gpu_info.stdout_lines }}"
  when: gpu_info.rc == 0

- name: Create monitoring script
  ansible.builtin.template:
    src: monitor.sh.j2
    dest: "{{ smart_analyzer_deploy_dir }}/monitor.sh"
    mode: '0755'
  when: smart_analyzer_create_monitoring_script | default(true)

- name: Display post-deployment instructions
  ansible.builtin.debug:
    msg:
      - "Next Steps:"
      - "1. Verify all services are running: cd {{ smart_analyzer_deploy_dir }} && docker compose ps"
      - "2. Check logs: docker compose logs -f"
      - "3. Monitor services: {{ smart_analyzer_deploy_dir }}/monitor.sh"
      - "4. Access Qdrant UI: http://{{ ansible_default_ipv4.address }}:{{ smart_analyzer_qdrant_port }}/dashboard"
      - "5. Test AI endpoint: curl http://localhost:{{ smart_analyzer_haproxy_port }}/v1/models"
